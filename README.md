# ğŸ§  Churn Insight API

API em Java/Spring Boot desenvolvida para o **Hackathon ONE**, responsÃ¡vel por calcular a probabilidade de churn (cancelamento) com base nas informaÃ§Ãµes do cliente.

Este repositÃ³rio contÃ©m a primeira versÃ£o funcional da API, incluindo:

* Endpoint de previsÃ£o (`/api/predict`)
* Estrutura de DTOs
* Modelo de prediÃ§Ã£o mockado
* Regras iniciais de cÃ¡lculo no utilitÃ¡rio `PredictionUtils`
* Swagger UI para testes rÃ¡pidos
* Estrutura para geraÃ§Ã£o de dataset sintÃ©tico

---

## ğŸš€ Tecnologias Utilizadas

* Java 17
* Spring Boot 3
* Maven
* H2 Database (in-memory)
* MapStruct
* Lombok
* Swagger (Springdoc OpenAPI)
* Python (para geraÃ§Ã£o do dataset)

---

## ğŸ“Œ Estrutura do Projeto

```
src/main/java/com/churninsight/api
â”œâ”€â”€ controller        â†’ PredictionController
â”œâ”€â”€ dto               â†’ CustomerInputDto, PredictionResponseDto
â”œâ”€â”€ mapper            â†’ PredictionMapper
â”œâ”€â”€ model             â†’ PredictionModel
â”œâ”€â”€ service           â†’ PredictionService
â””â”€â”€ util              â†’ PredictionUtils

data/
â”œâ”€â”€ .gitkeep
â””â”€â”€ scripts/
    â”œâ”€â”€ call_dataset_churn.py
    â””â”€â”€ .gitkeep
```

Arquitetura simples, modular e preparada para evoluÃ§Ã£o pelo time.

---

## ğŸ”® Endpoint Principal

### **POST /api/predict**

Envia dados de um cliente e recebe uma previsÃ£o calculada com base nas regras mockadas.

---

### **Exemplo de JSON enviado**

```json
{
  "contractMonths": 12,
  "paymentDelays": 1,
  "monthlyUsage": 230.5,
  "planType": "PREMIUM"
}
```

### **Exemplo de resposta**

```json
{
  "id": 1,
  "prediction": "No Churn",
  "probability": 0.125
}
```

---

## ğŸ“Š Regras de CÃ¡lculo (MVP)

A lÃ³gica inicial estÃ¡ centralizada em `PredictionUtils` e serve como **baseline para o time ajustar e evoluir**.

Cada atributo contribui com pesos positivos ou negativos para um *score*, normalizado entre **0 e 1**.

Essa camada poderÃ¡ futuramente ser substituÃ­da por:

* Modelo real de Machine Learning
* IntegraÃ§Ã£o com Python
* MicroserviÃ§o dedicado Ã  prediÃ§Ã£o
* Ajustes manuais da equipe de Data Science

---

## ğŸ§ Dataset SintÃ©tico (para Data Science)

O projeto inclui uma estrutura destinada Ã  geraÃ§Ã£o de dataset fictÃ­cio com **10.000 clientes**, usado para anÃ¡lises exploratÃ³rias (EDA), engenharia de atributos e modelagem supervisionada.

### ğŸ“ Estrutura

```
data/
â”œâ”€â”€ .gitkeep
â””â”€â”€ scripts/
    â”œâ”€â”€ call_dataset_churn.py
    â””â”€â”€ .gitkeep
```

O CSV gerado **nÃ£o Ã© versionado**, para evitar arquivos grandes no repositÃ³rio.

---

### ğŸ“„ Sobre o Script `call_dataset_churn.py`

O script gera dados sintÃ©ticos contendo:

**Dados do cliente**

* `name`, `age`, `city`, `state`
* `signup_date`

**Comportamento**

* `monthly_usage`
* `logins_per_month`
* `device_type`
* `plan_type`

**Pagamentos**

* `payment_delays`
* `late_payments_last_6m`
* `on_time_payment_ratio`

**Atributos para ML**

* `churn` (0 ou 1)
* `churn_probability` (score calculado)

---

### â–¶ï¸ Como gerar o dataset

No terminal:

```bash
cd data/scripts
python call_dataset_churn.py
```

O arquivo serÃ¡ gerado automaticamente em:

```
data/churn_customers_dataset.csv
```

---

## ğŸ”§ Como Executar a API

```bash
mvn spring-boot:run
```

A API estarÃ¡ disponÃ­vel em:

```
http://localhost:8080
```

### Swagger UI

```
http://localhost:8080/swagger-ui.html
```

---

## ğŸ§ª Testando com Postman / Insomnia

1. Crie uma requisiÃ§Ã£o **POST**
2. Use o endpoint:

```
http://localhost:8080/api/predict
```

3. Envie o JSON de exemplo.

---

## ğŸ¤ ContribuiÃ§Ã£o do Time

Este projeto foi iniciado para o Hackathon ONE e serÃ¡ evoluÃ­do em equipe.

ContribuiÃ§Ãµes bem-vindas:

* Ajustes nas regras de churn
* EvoluÃ§Ã£o do modelo de prediÃ§Ã£o
* RefatoraÃ§Ãµes de arquitetura
* CriaÃ§Ã£o de testes automatizados
* ExpansÃ£o do dataset
* ImplementaÃ§Ã£o de ML real

---


README TÃ‰CNICO â€” ENGENHARIA DE DADOS


ğŸ“Š Churn Insight â€” Pipeline de Engenharia de Dados
ğŸ“Œ VisÃ£o Geral

Este projeto implementa um pipeline completo de engenharia de dados para tratamento, padronizaÃ§Ã£o e preparaÃ§Ã£o de dados de churn de clientes de telecomunicaÃ§Ãµes, com foco em qualidade, governanÃ§a e preparo para machine learning e consumo analÃ­tico.

ğŸ—‚ï¸ Fonte dos Dados

Dataset pÃºblico: Telco Customer Churn

Origem: CSV hospedado em repositÃ³rio GitHub

IngestÃ£o direta via pandas.read_csv()

ğŸ—ï¸ Arquitetura do Pipeline
IngestÃ£o (CSV)
   â†“
PadronizaÃ§Ã£o de colunas
   â†“
TraduÃ§Ã£o e normalizaÃ§Ã£o de valores
   â†“
Tratamento de tipos e nulos
   â†“
Feature Engineering
   â†“
PreparaÃ§Ã£o para ML
   â†“
ExportaÃ§Ã£o do dataset tratado

ğŸ”§ Tecnologias Utilizadas

Python 3

Pandas

NumPy

Scikit-learn

Matplotlib / Seaborn (exploraÃ§Ã£o)

ğŸ§¹ Etapas de Tratamento dos Dados
âœ”ï¸ PadronizaÃ§Ã£o

NormalizaÃ§Ã£o de nomes de colunas (snake_case)

RemoÃ§Ã£o de acentos e caracteres especiais

PadronizaÃ§Ã£o de strings (lowercase)

âœ”ï¸ Qualidade

ConversÃ£o explÃ­cita de colunas numÃ©ricas

Tratamento de valores nulos

RemoÃ§Ã£o de registros duplicados

ValidaÃ§Ã£o de tipos

âœ”ï¸ Feature Engineering

CriaÃ§Ã£o de ticket_medio

CriaÃ§Ã£o de cliente_novo

Mapeamento da variÃ¡vel target (evasao)

ğŸ§  PreparaÃ§Ã£o para Machine Learning

SeparaÃ§Ã£o de features e target

IdentificaÃ§Ã£o automÃ¡tica de colunas categÃ³ricas e numÃ©ricas

Pipeline com:

StandardScaler para variÃ¡veis numÃ©ricas

OneHotEncoder para categÃ³ricas

LogisticRegression como modelo base

ğŸ“ SaÃ­da do Pipeline

Arquivo final gerado:

churn_telco_dados_tratados.csv


Dataset limpo, modelado e pronto para:

Machine Learning

Dashboards analÃ­ticos

APIs de inferÃªncia

Camadas Silver / Gold

ğŸ” GovernanÃ§a de Dados

Dados anonimizados para fins analÃ­ticos

PadronizaÃ§Ã£o consistente de schema

Pipeline reprodutÃ­vel e versionÃ¡vel

Pronto para integraÃ§Ã£o com ambientes corporativos

ğŸš€ PrÃ³ximos Passos

IntegraÃ§Ã£o com Data Lake / Lakehouse

Versionamento de dados

Monitoramento de qualidade

Deploy em ambiente cloud (Azure / Databricks)

